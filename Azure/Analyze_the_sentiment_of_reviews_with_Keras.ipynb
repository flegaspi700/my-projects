{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-YQXLdAOXbj",
        "outputId": "11fa46be-74c4-4c90-d661-bfb1f56e15cf"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import imdb\n",
        "top_words = 10000\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=top_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JamwAbttOoKL",
        "outputId": "405b1bae-674f-40e2-c2fe-a2ce5e2eb45a"
      },
      "outputs": [],
      "source": [
        "x_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9hyE-h5Oy8f",
        "outputId": "692ebced-7553-48ce-f4c0-0dc14283a7a7"
      },
      "outputs": [],
      "source": [
        "imdb.get_word_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCjO1wMaO3nV",
        "outputId": "2b6d05a0-4ce0-4e74-9002-e9f86d190d69"
      },
      "outputs": [],
      "source": [
        "word_dict = imdb.get_word_index()\n",
        "word_dict = { key:(value + 3) for key, value in word_dict.items() }\n",
        "word_dict[''] = 0  # Padding\n",
        "word_dict['>'] = 1 # Start\n",
        "word_dict['?'] = 2 # Unknown word\n",
        "reverse_word_dict = { value:key for key, value in word_dict.items() }\n",
        "print(' '.join(reverse_word_dict[id] for id in x_train[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUvcbgmePEn9"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing import sequence\n",
        "max_review_length = 500\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=max_review_length)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=max_review_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5w0xrl_8PHDA",
        "outputId": "6eb55743-6b92-48b0-c8f0-83338a6da949"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "from keras.layers.embeddings import Embedding\r\n",
        "from keras.layers import Flatten\r\n",
        "\r\n",
        "embedding_vector_length = 32\r\n",
        "model = Sequential()\r\n",
        "model.add(Embedding(top_words, embedding_vector_length, input_length=max_review_length))\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(18, activation='relu')) #\r\n",
        "model.add(Dense(18, activation='relu'))\r\n",
        "model.add(Dense(1, activation='sigmoid')) #one neuron because the ultimate goal of the network is to predict one output â€” namely, a sentiment score from 0.0 to 1.0\r\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\r\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_9EmO_1PMaP",
        "outputId": "5ccc804d-5891-4f53-8342-4a9faa338232"
      },
      "outputs": [],
      "source": [
        "hist = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=3, batch_size=32)\r\n",
        "#make 5 forward and backward passes through the model\r\n",
        "#batch_size=128 tells Keras to use 128 training samples at a time to train the network. \r\n",
        "#Larger batch sizes speed the training time (fewer passes are required in each epoch to consume all of the training data), \r\n",
        "# but smaller batch sizes sometimes increase accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "sxHuj6KlPOsm",
        "outputId": "48197604-cc21-4832-b219-0e1df625f36d"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "sns.set()\n",
        "acc = hist.history['accuracy']\n",
        "val = hist.history['val_accuracy']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, '-', label='Training accuracy')\n",
        "plt.plot(epochs, val, ':', label='Validation accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='upper left')\n",
        "plt.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "fpxNFWQeQSjK",
        "outputId": "1c3fbcba-c617-4df1-d295-97bf022363a8"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "sns.set()\n",
        "loss = hist.history['loss']\n",
        "val_loss = hist.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, loss, '-', label='Training loss')\n",
        "plt.plot(epochs, val_loss, ':', label='Validation loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='upper left')\n",
        "plt.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeneAXsKPQqB",
        "outputId": "d6dd4ca1-850b-4e5f-c020-bd0b47a48c76"
      },
      "outputs": [],
      "source": [
        "scores = model.evaluate(x_test, y_test, verbose=0)\r\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1] * 100))\r\n",
        "#base code Accuracy: 87.57%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAP_EyB8Rw_b"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import numpy as np\n",
        "\n",
        "def analyze(text):\n",
        "    # Prepare the input by removing punctuation characters, converting\n",
        "    # characters to lower case, and removing words containing numbers\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    text = text.translate(translator)\n",
        "    text = text.lower().split(' ')\n",
        "    text = [word for word in text if word.isalpha()]\n",
        "\n",
        "    # Generate an input tensor\n",
        "    input = [1]\n",
        "    for word in text:\n",
        "        if word in word_dict and word_dict[word] < top_words:\n",
        "            input.append(word_dict[word])\n",
        "        else:\n",
        "            input.append(2)\n",
        "    padded_input = sequence.pad_sequences([input], maxlen=max_review_length)\n",
        "\n",
        "    # Invoke the model and return the result\n",
        "    result = model.predict(np.array([padded_input][0]))[0][0]\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfRfixbqR0BX",
        "outputId": "73f8e1be-3d1e-4b3e-dd8f-408d2b295f9c"
      },
      "outputs": [],
      "source": [
        "analyze('Easily the most stellar experience I have ever had.')\r\n",
        "#0.95096385 base code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7QNAts6R2Kq",
        "outputId": "50042fba-c21a-49b7-f056-5caf056cf324"
      },
      "outputs": [],
      "source": [
        "analyze('The long lines and poor customer service really turned me off.')\r\n",
        "#0.4276932 base code"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Analyze the sentiment of reviews with Keras.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.1 64-bit",
      "name": "python391jvsc74a57bd08f0e6e8876776058453f48ad7c7dcdebdb8994a74dd96d3c38b5ba45b7b9008d"
    },
    "language_info": {
      "name": "python",
      "version": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}